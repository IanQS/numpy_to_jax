{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1005520e-0e0c-4f4e-a82e-b5bfbd3049f7",
   "metadata": {},
   "source": [
    "# Jax's vmap\n",
    "\n",
    "## Lesson Goals:\n",
    "\n",
    "By the end of this lesson, you will understand how and where to use `jax`'s `vmap` operation.\n",
    "\n",
    "## Core Concepts:\n",
    "\n",
    "- `vmap`\n",
    "- softmax-regression\n",
    "- gaussian PDF\n",
    "- Neural Network Inference\n",
    "\n",
    "## Concepts In action:\n",
    "\n",
    "- Easy: [lotka-volterra](../case_studies/lotka-volterra/README.md)\n",
    "\n",
    "- Intermediate: [leaky_integrate_and_fire](../case_studies/leaky_integrate_and_fire/README.md)\n",
    " \n",
    "- Advanced: [gaussian_mixture_model](../case_studies/gaussian_mixture_model/README.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d089337-0683-4cc8-9aae-4a0c7443fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax.scipy import stats\n",
    "import numpy as np\n",
    "from jax import vmap\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b0923-f643-43a2-a5c5-cc01c81b6d79",
   "metadata": {},
   "source": [
    "# Example: Batched Neural Network Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba6265c-dd7d-4d07-900c-7f70186431ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network parameters\n",
    "W1 = jnp.array([[0.2, 0.4], [0.5, 0.3]])  # Shape (2, 2)\n",
    "W2 = jnp.array([0.6, 0.7])                # Shape (2,)\n",
    "\n",
    "# Activation function\n",
    "def relu(x):\n",
    "    return jnp.maximum(0, x)\n",
    "\n",
    "# Single forward pass\n",
    "def forward_pass(x, W1, W2):\n",
    "    \"\"\"\n",
    "    TODO: Your code here\n",
    "    1) Take the dot product between W1 and x\n",
    "    2) apply the relu\n",
    "    3) return the dot product between W2 and the relu result\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Vectorized forward pass using vmap\n",
    "\n",
    "batched_forward_pass = ... # TODO: Your code here! vmap(forward_pass, ...)\n",
    "\n",
    "# Example batched input data\n",
    "X_batch = jnp.array([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])  # Shape (3, 2)\n",
    "\n",
    "# Compute the output for the batch\n",
    "batch_output = batched_forward_pass(X_batch, W1, W2)\n",
    "print(batch_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e4af4f-422e-45b3-874f-ab1e483533d9",
   "metadata": {},
   "source": [
    "# Calculating the Gaussian PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6292b5-f696-4408-9caf-f70066fbc78e",
   "metadata": {},
   "source": [
    "![](../assets/gaussian_pdf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60315ea0-0c54-4734-ad0f-d9fa0e06cfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0, 0])  # Mean vector\n",
    "Sigma = np.array([[1, 0], [0, 1]])  # Covariance matrix\n",
    "X = np.array([[1, 1], [2, 2], [3, 3]])  # Point to evaluate the PDF\n",
    "\n",
    "# Arguments implicitly passed in. Done to keep the code cleaner for the example\n",
    "k = mu.shape[0]\n",
    "t1 = (2 * jnp.pi) ** (-k / 2)\n",
    "t2 = jnp.linalg.det(Sigma) ** (-0.5)\n",
    "inv = jnp.linalg.inv(Sigma)\n",
    "\n",
    "def gaussian_pdf_v(x_vec, mu_vec, Sigma):\n",
    "    \"\"\"\n",
    "    # TODO: implement the single-sample equivalent of `to_exp` in the gaussian_pdf/\n",
    "    #       the elements to be exponentiated in the image above\n",
    "    \"\"\"\n",
    "    diff = x_vec - mu_vec\n",
    "    to_exp = ... # TODO: Your code here! vmap(forward_pass, ...)\n",
    "    \n",
    "    return t1 * t2 * jnp.exp(to_exp)\n",
    "\n",
    "def gaussian_pdf(x_mat, mu_mat) -> np.array:\n",
    "    diff = x_mat - mu_mat\n",
    "    ###############################################################\n",
    "    to_exp = -0.5 * jnp.sum(diff @ inv * diff, axis=1)\n",
    "    ###############################################################\n",
    "    return t1 * t2 * jnp.exp(to_exp)\n",
    "\n",
    "\n",
    "vmapped_gaussian = vmap(gaussian_pdf_v, in_axes=(0, None, None))\n",
    "vmap_gauss_res = vmapped_gaussian(X, mu, Sigma)\n",
    "\n",
    "\n",
    "print(\"VMapped-Gaussian PDF correct?\", jnp.allclose(\n",
    "    vmap_gauss_res, \n",
    "    stats.multivariate_normal.pdf(X, mu, Sigma)\n",
    "))\n",
    "\n",
    "print(\"Typical-Gaussian PDF correct?\", jnp.allclose(\n",
    "    gaussian_pdf(X, mu, Sigma), \n",
    "    stats.multivariate_normal.pdf(X, mu, Sigma)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4794415a-102c-4b9b-9553-afb6cece1445",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8b4a24-e885-4741-8ec3-c8b3129ef074",
   "metadata": {},
   "source": [
    "![](../assets/softmax_regression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81ffd1-6b20-495e-a050-5e9907654135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example data\n",
    "X = jnp.array([[1, 2], [2, 3], [3, 4]])  # Batch of inputs\n",
    "W = jnp.array([[0.2, 0.8], [0.5, 0.1]])  # Weight matrix\n",
    "b = jnp.array([0.1, -0.2])  # Bias vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38488af3-9e0e-48f9-af9f-63c0600ff96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_regression(X, W, b):\n",
    "    logits = jnp.dot(X, W) + b\n",
    "    exp_logits = jnp.exp(logits)\n",
    "    probabilities = exp_logits / jnp.sum(exp_logits, axis=-1, keepdims=True)\n",
    "    return probabilities\n",
    "\n",
    "# Calculate softmax probabilities for the batch of inputs\n",
    "probabilities = softmax_regression(X, W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b9e321-84d7-4c6b-8fe6-fe6580134695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_softmax_regression(x, W, b):\n",
    "    \"\"\"\n",
    "    TODO: Implement the equivalent of the softmax_regression above on a single row of x\n",
    "    \"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Vectorize the single input calculation\n",
    "vectorized_softmax_regression = vmap(single_softmax_regression, in_axes=(0, None, None))\n",
    "\n",
    "# Calculate softmax probabilities using vmap\n",
    "probabilities_vmap = vectorized_softmax_regression(X, W, b)\n",
    "print(f\"Vmapped Softmax Regression equal to vectorized?: {np.allclose(probabilities, probabilities_vmap)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f199f4-b886-4c9a-9b9e-7495c7f21463",
   "metadata": {},
   "source": [
    "# Further Exercises: \n",
    "\n",
    "## 1) Read up on [jax.pmap](https://jax.readthedocs.io/en/latest/_autosummary/jax.pmap.html)\n",
    "\n",
    "`pmap` is a parallel map across devices and is useful for scaling across devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9af2a0-8166-4cef-b538-db7722474301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
