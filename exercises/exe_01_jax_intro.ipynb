{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8623bd1c-abab-4eaf-bd15-4f78d335de0b",
   "metadata": {},
   "source": [
    "# Intro to Jax a.k.a swapping `np.X` for `jnp.X`\n",
    "\n",
    "## Lesson Goals:\n",
    "\n",
    "By the end of this lesson, you will have an understanding of how to migrate from `numpy` to `jax`, and get a feel for how similar the two libraries can be. "
   ]
  },
  {
   "cell_type": "code",
   "id": "11ba69c5-8ea0-4d65-a69d-f888d06d2f7d",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "81f80b94-03ee-46a6-86b5-5e773b4f1095",
   "metadata": {},
   "source": [
    "# What is Jax?\n",
    "\n",
    "To put it simply, Jax is numpy for various hardware accelerators. However, it offers much more than that by providing higher-level abstractions, utilizing a different backend (XLA), and supporting automatic differentiation.\n",
    "\n",
    "From the website:\n",
    "\n",
    "> JAX is NumPy on the CPU, GPU, and TPU, with great automatic differentiation for high-performance machine learning research.\n",
    "\n",
    "Despite these capabilities, not all concepts and idioms from NumPy translate directly, and there are certain ‼️sharp edges‼️ of which you should be aware."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256009c1-261b-4f65-a78c-177f9997e390",
   "metadata": {},
   "source": [
    "## Sample Exercises\n",
    "\n",
    "Below, we provide some exercises to help you become familiar with Jax and Numpy. The solutions are more or less what you might expect from a drop-in replacement."
   ]
  },
  {
   "cell_type": "code",
   "id": "bf3e2125-7b08-4425-b542-59481cd9df1c",
   "metadata": {},
   "source": [
    "\n",
    "def dot_product():\n",
    "    v = np.random.rand(10)\n",
    "    M = np.random.rand(10, 5)\n",
    "\n",
    "    expected_result = np.dot(v, M)\n",
    "    actual_result = ... # Your code here\n",
    "\n",
    "    assert jnp.allclose(expected_result, actual_result)\n",
    "    print(\"Dot product passed\")\n",
    "    \n",
    "\n",
    "def is_even_filter():\n",
    "    to_filter_np = np.asarray([1, 2, 3, 5, 10, 20])\n",
    "    expected_result = to_filter_np[to_filter_np % 2 == 0]\n",
    "\n",
    "    to_filter_jnp = jnp.asarray(to_filter_np)\n",
    "    actual_result = ... # Your code here\n",
    "\n",
    "    assert jnp.allclose(expected_result, actual_result)\n",
    "    print(\"is_even_filter passed\")\n",
    "\n",
    "def top_n_of_norm_squared():\n",
    "    M = np.random.rand(10, 5)\n",
    "    TOP_N = 5\n",
    "    \n",
    "    expected_result = np.sort(np.linalg.norm(M @ M.T, axis=1))[::-1][:TOP_N]\n",
    "\n",
    "    jnp_M = jnp.asarray(M)\n",
    "    actual_result = ... # Your code here\n",
    "\n",
    "    assert jnp.allclose(expected_result, actual_result)\n",
    "    print(\"top_n_of_norm_squared passed\")\n",
    "\n",
    "\n",
    "def hadamard():\n",
    "    M = np.random.rand(10, 5)\n",
    "    expected_result = M * M\n",
    "\n",
    "    jnp_M = jnp.asarray(M)\n",
    "    actual_result = ... # Your code here\n",
    "\n",
    "    assert jnp.allclose(expected_result, actual_result)\n",
    "    print(\"hadamard passed\")\n",
    "    \n",
    "    \n",
    "\n",
    "dot_product()\n",
    "is_even_filter()\n",
    "top_n_of_norm_squared()\n",
    "hadamard()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
